<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><meta name="viewport" content="width=device-width, initial-scale=1" /><title>MLIR.AST.Dialect.Tensor</title><link href="linuwial.css" rel="stylesheet" type="text/css" title="Linuwial" /><link rel="stylesheet" type="text/css" href="quick-jump.css" /><link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400i,700" /><script src="haddock-bundle.min.js" async="async" type="text/javascript"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { processClass: "mathjax", ignoreClass: ".*" } });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script></head><body><div id="package-header"><span class="caption">mlir-hs-0.1.0.0</span><ul class="links" id="page-menu"><li><a href="src/MLIR.AST.Dialect.Tensor.html">Source</a></li><li><a href="index.html">Contents</a></li><li><a href="doc-index.html">Index</a></li></ul></div><div id="content"><div id="module-header"><table class="info"><tr><th>Safe Haskell</th><td>None</td></tr><tr><th>Language</th><td>Haskell2010</td></tr></table><p class="caption">MLIR.AST.Dialect.Tensor</p></div><div id="table-of-contents"><div id="contents-list"><p class="caption" onclick="window.scrollTo(0,0)">Contents</p><ul><li><a href="#g:1">cast</a></li><li><a href="#g:2">collapse_shape</a></li><li><a href="#g:3">dim</a></li><li><a href="#g:4">empty</a></li><li><a href="#g:5">expand_shape</a></li><li><a href="#g:6">extract</a></li><li><a href="#g:7">extract_slice</a></li><li><a href="#g:8">from_elements</a></li><li><a href="#g:9">gather</a></li><li><a href="#g:10">generate</a></li><li><a href="#g:11">insert</a></li><li><a href="#g:12">insert_slice</a></li><li><a href="#g:13">pack</a></li><li><a href="#g:14">pad</a></li><li><a href="#g:15">parallel_insert_slice</a></li><li><a href="#g:16">rank</a></li><li><a href="#g:17">reshape</a></li><li><a href="#g:18">scatter</a></li><li><a href="#g:19">splat</a></li><li><a href="#g:20">unpack</a></li><li><a href="#g:21">yield</a></li></ul></div></div><div id="synopsis"><details id="syn"><summary>Synopsis</summary><ul class="details-toggle" data-details-id="syn"><li class="src short"><span class="keyword">pattern</span> <a href="#v:Cast">Cast</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand</li><li class="src short"><a href="#v:cast">cast</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a></li><li class="src short"><span class="keyword">pattern</span> <a href="#v:Dim">Dim</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; operand -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand</li><li class="src short"><a href="#v:dim">dim</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a></li><li class="src short"><span class="keyword">pattern</span> <a href="#v:Empty">Empty</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; [operand] -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand</li><li class="src short"><a href="#v:empty">empty</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; [<a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a>] -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a></li><li class="src short"><a href="#v:extract">extract</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; [<a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a>] -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a></li><li class="src short"><span class="keyword">pattern</span> <a href="#v:FromElements">FromElements</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; [operand] -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand</li><li class="src short"><a href="#v:from_elements">from_elements</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; [<a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a>] -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a></li><li class="src short"><a href="#v:generate">generate</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; [<a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a>] -&gt; <a href="MLIR-AST-Builder.html#t:RegionBuilderT" title="MLIR.AST.Builder">RegionBuilderT</a> m () -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a></li><li class="src short"><a href="#v:insert">insert</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; [<a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a>] -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a></li><li class="src short"><span class="keyword">pattern</span> <a href="#v:Rank">Rank</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand</li><li class="src short"><a href="#v:rank">rank</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a></li><li class="src short"><span class="keyword">pattern</span> <a href="#v:Reshape">Reshape</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; operand -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand</li><li class="src short"><a href="#v:reshape">reshape</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a></li><li class="src short"><span class="keyword">pattern</span> <a href="#v:Splat">Splat</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand</li><li class="src short"><a href="#v:splat">splat</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a></li><li class="src short"><span class="keyword">pattern</span> <a href="#v:Yield">Yield</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand</li><li class="src short"><a href="#v:yield">yield</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:EndOfBlock" title="MLIR.AST.Builder">EndOfBlock</a></li></ul></details></div><div id="interface"><a href="#g:1" id="g:1"><h1>cast</h1></a><div class="doc"><p>Convert a tensor from one type to an equivalent type without changing any
 data elements. The source and destination types must both be tensor types
 with the same element type. If both are ranked, then the rank should be the
 same and static dimensions should match. The operation is invalid if
 converting to a mismatching constant dimension.</p><p>Example:</p><pre>// Convert from unknown rank to rank 2 with unknown dimension sizes.
%2 = tensor.cast %1 : tensor&lt;*xf32&gt; to tensor&lt;?x?xf32&gt;

// Convert to a type with more known dimensions.
%3 = tensor.cast %2 : tensor&lt;?x?xf32&gt; to tensor&lt;4x?xf32&gt;

// Discard static dimension and rank information.
%4 = tensor.cast %3 : tensor&lt;4x?xf32&gt; to tensor&lt;?x?xf32&gt;
%5 = tensor.cast %4 : tensor&lt;?x?xf32&gt; to tensor&lt;*xf32&gt;
</pre></div><div class="top"><p class="src"><span class="keyword">pattern</span> <a id="v:Cast" class="def">Cast</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#Cast" class="link">Source</a> <a href="#v:Cast" class="selflink">#</a></p><div class="doc"><p>A pattern for <code>tensor.cast</code>.</p></div></div><div class="top"><p class="src"><a id="v:cast" class="def">cast</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#cast" class="link">Source</a> <a href="#v:cast" class="selflink">#</a></p><div class="doc"><p>A builder for <code>tensor.cast</code>.</p></div></div><a href="#g:2" id="g:2"><h1>collapse_shape</h1></a><div class="doc"><p>The <code>tensor.collapse_shape</code> op produces a new tensor with a smaller
 rank whose sizes are a reassociation of the original <code>src</code>.</p><p>A reassociation is defined as a continuous grouping of dimensions and is
 represented with an array of DenseI64ArrayAttr attribute.</p><p>The verification rule is that the reassociation maps are applied to the
 operand tensor with the higher rank to obtain the result tensor with the
 smaller rank.</p><p>The result tensor type of a reshape can be zero-ranked if the operand
 tensor type is statically shaped with all dimensions being unit extent. In
 such case the reassociation map is empty.</p><p>Examples:</p><pre>// Dimension collapse (i, j) -&gt; i' and k -&gt; k'
%b = tensor.collapse_shape %a [[0, 1], [2]]
    : tensor&lt;?x?x?xf32&gt; into tensor&lt;?x?xf32&gt;
</pre></div><a href="#g:3" id="g:3"><h1>dim</h1></a><div class="doc"><p>The <code>tensor.dim</code> operation takes a tensor and a dimension operand of type
 <code>index</code>. It returns the size of the requested dimension of the given
 tensor. If the dimension index is out of bounds, the behavior is undefined.</p><p>The specified tensor type is that of the first operand.</p><p>Example:</p><pre>// Always returns 4, can be constant folded:
%c0 = arith.constant 0 : index
%x = tensor.dim %A, %c0 : tensor&lt;4x?xf32&gt;

// Returns the dynamic dimension of %A.
%c1 = arith.constant 1 : index
%y = tensor.dim %A, %c1 : memref&lt;4x?xf32&gt;

// Equivalent generic form:
%x = &quot;tensor.dim&quot;(%A, %c0) : (memref&lt;4x?xf32&gt;, index) -&gt; index
%y = &quot;tensor.dim&quot;(%A, %c1) : (memref&lt;4x?xf32&gt;, index) -&gt; index
</pre></div><div class="top"><p class="src"><span class="keyword">pattern</span> <a id="v:Dim" class="def">Dim</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; operand -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#Dim" class="link">Source</a> <a href="#v:Dim" class="selflink">#</a></p><div class="doc"><p>A pattern for <code>tensor.dim</code>.</p></div></div><div class="top"><p class="src"><a id="v:dim" class="def">dim</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#dim" class="link">Source</a> <a href="#v:dim" class="selflink">#</a></p><div class="doc"><p>A builder for <code>tensor.dim</code>.</p></div></div><a href="#g:4" id="g:4"><h1>empty</h1></a><div class="doc"><p><code>tensor.empty</code> is an operation that defines a tensor of a particular shape.
 The shape could be dynamic or static. The contents of the tensor are
 unspecified and the only purpose of the op result is to materialize the
 specified shape in IR and make it available to other transformations.</p><p><code>tensor.empty</code> is useful in transformations that expect destination style
 ops. I.e., ops that implement <code>DestinationStyleOpInterface</code>. Ops that are
 not in destination style can be made compatible with such transformations
 with a <code>tensor.empty</code> destination.</p><p>Note: This op can be lowered to a <code>bufferization.alloc_tensor</code>, at which
 point it turns into an explicit buffer allocation.</p></div><div class="top"><p class="src"><span class="keyword">pattern</span> <a id="v:Empty" class="def">Empty</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; [operand] -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#Empty" class="link">Source</a> <a href="#v:Empty" class="selflink">#</a></p><div class="doc"><p>A pattern for <code>tensor.empty</code>.</p></div></div><div class="top"><p class="src"><a id="v:empty" class="def">empty</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; [<a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a>] -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#empty" class="link">Source</a> <a href="#v:empty" class="selflink">#</a></p><div class="doc"><p>A builder for <code>tensor.empty</code>.</p></div></div><a href="#g:5" id="g:5"><h1>expand_shape</h1></a><div class="doc"><p>The <code>tensor.expand_shape</code> op produces a new tensor with a higher
 rank whose sizes are a reassociation of the original <code>src</code>.</p><p>A reassociation is defined as a continuous grouping of dimensions and is
 represented with an array of DenseI64ArrayAttr attribute.</p><p>The verification rule is that the reassociation maps are applied to the
 result tensor with the higher rank to obtain the operand tensor with the
 smaller rank.</p><p>The operand tensor type of a reshape can be zero-ranked if the result
 tensor type is statically shaped with all dimensions being unit extent. In
 such cases the reassociation map is empty.</p><p>Examples:</p><pre>// Dimension expansion i -&gt; (i', j') and (k) -&gt; (k')
%b = tensor.expand_shape %a [[0, 1], [2]]
    : tensor&lt;?x?xf32&gt; into tensor&lt;?x?x?xf32&gt;
</pre></div><a href="#g:6" id="g:6"><h1>extract</h1></a><div class="doc"><p>The <code>tensor.extract</code> op reads a ranked tensor and returns one element as
 specified by the given indices. The result of the op is a value with the
 same type as the elements of the tensor. The arity of indices must match
 the rank of the accessed value. All indices should all be of <code>index</code> type.</p><p>Example:</p><pre>%4 = tensor.extract %t[%1, %2] : tensor&lt;4x4xi32&gt;
%5 = tensor.extract %rt[%1, %2] : tensor&lt;?x?xi32&gt;
</pre></div><div class="top"><p class="src"><a id="v:extract" class="def">extract</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; [<a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a>] -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#extract" class="link">Source</a> <a href="#v:extract" class="selflink">#</a></p><div class="doc"><p>A builder for <code>tensor.extract</code>.</p></div></div><a href="#g:7" id="g:7"><h1>extract_slice</h1></a><div class="doc"><p>The &quot;extract_slice&quot; operation extract a tensor from another tensor as
 specified by the operation's offsets, sizes and strides arguments.</p><p>The extract_slice operation supports the following arguments:</p><ul><li>source: the &quot;base&quot; tensor from which to extract a slice.</li><li>offsets: tensor-rank number of offsets into the &quot;base&quot; tensor from which
            to extract the slice.</li><li>sizes: tensor-rank number of sizes which specify the sizes of the result
          tensor type.</li><li>strides: tensor-rank number of strides specifying subsampling in each
            dimension.</li></ul><p>The representation based on offsets, sizes and strides support a
 partially-static specification via attributes specified through the
 <code>static_offsets</code>, <code>static_sizes</code> and <code>static_strides</code> arguments. A special
 sentinel value ShapedType::kDynamic and
 ShapedType::kDynamic encodes that the corresponding entry has
 a dynamic value.</p><p>After buffer allocation, the &quot;extract_slice&quot; op is expected to lower into a
 memref.subview op.</p><p>An extract_slice operation may additionally reduce the rank of the resulting
 tensor by removing dimensions that are statically known to be of size 1.
 This rank-reduction behavior is not required by the op semantics: this
 flexibility allows to progressively drop unit dimensions while lowering
 between different flavors of ops on that operate on tensors.</p><p>#### Verification vs Inference in the rank-reduced case</p><p>Note that there may be multiple ways to infer a resulting rank-reduced type.
   e.g. 1x6x1 could potentially rank-reduce to either 1x6 or 6x1 2-D shapes.</p><p>To disambiguate, the inference helpers <code>inferCanonicalRankReducedResultType</code>
 only drop the first unit dimensions, in order:
   e.g. 1x6x1 rank-reduced to 2-D will infer the 6x1 2-D shape, but not 1x6.</p><p>Verification however has access to result type and does not need to infer.
 The verifier calls <code>isRankReducedType(getSource(), getResult())</code> to
 determine whether the result type is rank-reduced from the source type.
 This computes a so-called rank-reduction mask, consisting of dropped unit
 dims, to map the rank-reduced type to the source type by dropping ones:
   e.g. 1x6 is a rank-reduced version of 1x6x1 by mask {2}
        6x1 is a rank-reduced version of 1x6x1 by mask {0}
        1x2x1x4 is a rank-reduced version of 1x1x2x1x1x4x1 by mask {1, 4, 6}
          (remaining common 1 dimensions are matched eagerly)</p><p>Example:</p><pre>// Rank-reducing extract_slice.
%1 = tensor.extract_slice %0[0, 0, 0][1, 16, 4][1, 1, 1] :
  tensor&lt;8x16x4xf32&gt; to tensor&lt;16x4xf32&gt;
%3 = tensor.extract_slice %2[%o0, 4, %o2][1, %sz1, 1][1, %st1, 1] :
  tensor&lt;8x16x4xf32&gt; to tensor&lt;1x?xf32&gt;
</pre></div><a href="#g:8" id="g:8"><h1>from_elements</h1></a><div class="doc"><p>Create a N-D tensor from a range of same-type arguments. The number of
 provided <code>elements</code> should equal to the number of the elements in the
 result type. The <code>elements</code> correspond to a flattened tensor.</p><p>Example:</p><pre>tensor.from_elements %a, %b, %c, %d, %e, %f :  tensor&lt;2x3xindex&gt;
</pre><p>will result in a tensor</p><dl><dt>[%a, %b, %c</dt><dd></dd><dt>%d, %e, %f</dt><dd>]</dd></dl></div><div class="top"><p class="src"><span class="keyword">pattern</span> <a id="v:FromElements" class="def">FromElements</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; [operand] -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#FromElements" class="link">Source</a> <a href="#v:FromElements" class="selflink">#</a></p><div class="doc"><p>A pattern for <code>tensor.from_elements</code>.</p></div></div><div class="top"><p class="src"><a id="v:from_elements" class="def">from_elements</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; [<a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a>] -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#from_elements" class="link">Source</a> <a href="#v:from_elements" class="selflink">#</a></p><div class="doc"><p>A builder for <code>tensor.from_elements</code>.</p></div></div><a href="#g:9" id="g:9"><h1>gather</h1></a><div class="doc"><p>The <code>gather</code> operation extracts a subset of the elements from a <code>source</code>
 tensor at the given indices.</p><p>In its most general form, the tensor of indices specifies all the coordinates
 of every element to extract (i.e. COO format, without the payload).
 The indices are expected to be confined to coordinate values that fit the
 range of the <code>source</code> tensor, otherwise the behavior is undefined.</p><p>The leading dimensions of the index tensor give the result tensor its leading
 dimensions. The trailing dimensions of the result tensor are obtained from
 the source tensor by omitting the dimensions specified in <code>gather_dims</code>
 (rank-reducing semantics) or setting them to <code>1</code> (rank-preserving semantics)
 (see examples).
 The trailing dimension of the index tensor contains the coordinates and is
 expected to have its size equal to the number of dimensions being gathered.
 This convention allows an idiomatic specification and lowering of &quot;gathering
 multiple N-D slices from the source tensor&quot;.</p><p>Note: in the examples below, we separate out the indexing part of the tensor
 type by a whitespace for readability purposes.</p><p>Example:</p><pre>    // For each 1x2 triple of coordinates in %indices, extract the
    // element (i.e. 0-D subset) at the coordinates triple in %source.
    //
    %out = tensor.gather %source[%indices] gather_dims([0, 1, 2]) :
      (tensor&lt;4x4x4xf32&gt;, tensor&lt;1x2x 3xindex&gt;) -&gt; tensor&lt;1x2x 1x1x1xf32&gt;

    // Note: result type may be further rank-reduced to tensor&lt;1x2x f32&gt;.
</pre><p>A slice variant is provided to allow specifying whole slices of the source
 tensor.</p><p>Example:</p><pre>    // For each 5x6 singleton of coordinates in %indices, extract the 2-D
    // slice %source[*, %indices[...]:%indices[...] + 1, *] with the indices
    // corresponding to the <code>gather_dims</code> attribute specified by %indices.
    //
    %out = tensor.gather %source[%indices] gather_dims([1]) :
      (tensor&lt;3x4x5xf32&gt;, tensor&lt;6x7x 1xindex&gt;) -&gt; tensor&lt;6x7x 3x1x5xf32&gt;

    // Note: result type may be further rank-reduced to tensor&lt;6x7x 3x5xf32&gt;.
</pre><p>The dimensions specified in the gather_dims attribute are ones for which the
 result tensor has size <code>1</code>.
 I.e. if the source type is <code>axbxcxd</code> and the coordinates are [1, 3], then
 the shape suffix is <code>ax1xcx1</code>.
 Gather also allows rank-reducing semantics where the shape <code>ax1xcx1</code> can be
 further simplified to <code>axc</code>.</p><p>The elemental type of the indices tensor can be any integer type.
 In the absence of target-specific or problem specific information the default
 type one should use is <code>index</code>.</p><p>This operation does not support unranked tensors.</p><p>An optional <code>unique</code> unit attribute may be specified to indicate that the
 coordinates in <code>indices</code> are statically guaranteed to be unique at runtime.
 Incorrectly setting the <code>unique</code> attribute when the coordinates are not truly
 unique is undefined behavior.</p><p>Only full slices are meant to be supported by this op, if one desires
 partial slices (e.g. strided windows) one should compose this op with other
 tensor ops (e.g. tensor.extract_slice). This is to avoid a slippery slope of
 complexity that would make the op unusable in practice.</p><p>At the tensor-level, the index tensor is specified in an AoS form (i.e.
 coordinate tuple is the most minor). It is the responsibility of further
 lowerings and bufferiation to implement various concrete layouts.</p><p>Note: As currently specified, the operation must lower to an abstraction that
 performs copies to the output tensor. This is because the buffer type system
 is currently not rich enough to allow multiple non-contiguous views in the
 same type. This is visible more clearly in a notional buffer version of the
 op:</p><pre>    // memref&lt;?x4x1xf32&gt; is a contiguous buffer of ?x4x1 elements.
    // gather from random source slices must copy to the contiguous output.
    %out = memref.gather %source[%indices] gather_dims([1]) :
      (memref&lt;4x4xf32&gt;, memref&lt;?x 1xindex&gt;) -&gt; memref&lt;?x 4x1xf32&gt;

    // Nested buffer support would allow gather to directly index into the
    // source buffer (i.e. represent a jagged view into the source).
    %out = memref.gather %source[%indices] gather_dims([1]) :
      (memref&lt;4x4xf32&gt;, memref&lt;?x 1xindex&gt;) -&gt; memref&lt;? x memref&lt;4x1xf32&gt;&gt;
</pre></div><a href="#g:10" id="g:10"><h1>generate</h1></a><div class="doc"><p>This operation creates a dynamically sized tensor with elements of any type.
 It expects one index operand per dynamic extent of the result tensor.</p><p>The body region defines the tensor's elements. It takes index operands as
 its region arguments that span the index space. The element at the given
 position is yielded with the <code>yield</code> operation (see <code>YieldOp</code>). There is
 no defined ordering to the invocations of the body. It is conceptually
 a &quot;parallel map&quot; operation.</p><p>Example:</p><pre>  %tnsr = tensor.generate %m, %n {
  ^bb0(%i : index, %j : index, %k : index):
    ...
    yield %elem : f32
  } : tensor&lt;?x3x?f32&gt;
</pre></div><div class="top"><p class="src"><a id="v:generate" class="def">generate</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; [<a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a>] -&gt; <a href="MLIR-AST-Builder.html#t:RegionBuilderT" title="MLIR.AST.Builder">RegionBuilderT</a> m () -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#generate" class="link">Source</a> <a href="#v:generate" class="selflink">#</a></p><div class="doc"><p>A builder for <code>tensor.generate</code>.</p></div></div><a href="#g:11" id="g:11"><h1>insert</h1></a><div class="doc"><p>The <code>tensor.insert</code> op inserts a scalar into a ranked tensor <code>dest</code> as
 specified by the operation's indices.</p><p>It returns a copy of <code>dest</code> with the indexed position updated to the value
 of <code>scalar</code>.</p><p>The arity of <code>indices </code>must match the rank of the tensor <code>dest</code>. All
 indices should be of <code>index</code> type.</p><p>Example:</p><pre>%4 = tensor.insert %t into %dest[%1, %2] : tensor&lt;4x4xi32&gt;
%5 = tensor.insert %rt into %dest[%1, %2] : tensor&lt;?x?xi32&gt;
</pre></div><div class="top"><p class="src"><a id="v:insert" class="def">insert</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; [<a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a>] -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#insert" class="link">Source</a> <a href="#v:insert" class="selflink">#</a></p><div class="doc"><p>A builder for <code>tensor.insert</code>.</p></div></div><a href="#g:12" id="g:12"><h1>insert_slice</h1></a><div class="doc"><p>The &quot;insert_slice&quot; operation insert a tensor <code>source</code> into another
 tensor <code>dest</code> as specified by the operation's offsets, sizes and strides
 arguments.</p><p>It returns a copy of <code>dest</code> with the proper slice updated with the value
 of <code>source</code>.</p><p>The insert_slice operation supports the following arguments:</p><ul><li>source: the tensor that is inserted.</li><li>dest: the tensor into which the source tensor is inserted.</li><li>offsets: tensor-rank number of offsets into the <code>dest</code> tensor into which
            the slice is inserted.</li><li>sizes: tensor-rank number of sizes which specify the sizes of the source
          tensor type.</li><li>strides: tensor-rank number of strides that specify subsampling in each
            dimension.</li></ul><p>The representation based on offsets, sizes and strides support a
 partially-static specification via attributes specified through the
 <code>static_offsets</code>, <code>static_sizes</code> and <code>static_strides</code> arguments. A special
 sentinel value ShapedType::kDynamic and
 ShapedType::kDynamic encodes that the corresponding entry has
 a dynamic value.</p><p>After buffer allocation, the &quot;insert_slice&quot; op is expected to lower into a
 memref.subview op.</p><p>An insert_slice operation may additionally specify insertion into a tensor
 of higher rank than the source tensor, along dimensions that are statically
 known to be of size 1.
 This rank-altering behavior is not required by the op semantics: this
 flexibility allows to progressively drop unit dimensions while lowering
 between different flavors of ops on that operate on tensors.
 The rank-altering behavior of tensor.insert_slice matches the rank-reducing
 behavior of tensor.extract_slice.</p><p>#### Verification in the rank-reduced case</p><p>The same verification discussion and mechanisms apply as for ExtractSliceOp.
 Unlike ExtractSliceOp however, there is no need for a specific inference.</p><p>Example:</p><pre>// Rank-altering insert_slice.
%1 = tensor.insert_slice %t into %0[0, 0, 0][1, 16, 4][1, 1, 1] :
  tensor&lt;16x4xf32&gt; into tensor&lt;8x16x4xf32&gt;
%3 = tensor.insert_slice %tt into %2[%o0, 4, %o2][1, %sz1, 1][1, %st1, 1] :
  tensor&lt;1x?xf32&gt; into tensor&lt;8x16x4xf32&gt;
</pre></div><a href="#g:13" id="g:13"><h1>pack</h1></a><div class="doc"><p>The pack operation converts an input tensor to a higher-dimensional tensor
 with a tiled and packed layout. The mandatory <code>inner_dims_pos</code> attribute
 specifies a permutation for the original dimensions, while <code>inner_tiles</code> is the
 tiling factor for each dimension. The optional attribute <code>outer_dims_perm</code>
 specifies the order for the tiled data dimension, while the attribute
 <code>padding_value</code> specifies a padding value at the boundary on non-perfectly
 divisible dimensions. Padding is optional:
 - If absent, it is UB if the tile does not perfectly divide the dimension.
 - If present, it will pad along high dimensions (high-padding) to make the
   tile complete.</p><p>Example NC_to_NCnc:</p><pre>%0 = tensor.pack %source inner_dims_pos = [0, 1]
  inner_tiles = [8, 32] into %dest : tensor&lt;128x256xf32&gt; -&gt; tensor&lt;16x8x8x32xf32&gt;
</pre><p>Example CK to KCck</p><pre>%0 = tensor.pack %source outer_dims_perm = [1, 0] inner_dims_pos = [0, 1]
  inner_tiles = [8, 32] into %dest : tensor&lt;128x256xf32&gt; -&gt; tensor&lt;8x16x8x32xf32&gt;
</pre><p>In all cases, dimension at position 0 in the input tensor (128) is tiled
 with a factor of 8, while dimension at position 1 (256) is tiled with a factor
 of 32. In the second example, the outer data dimensions are interchanged
 according to <code>outer_dims_perm</code>.</p><p>Example NC_to_NCnc with padding:</p><pre>%0 = tensor.pack %arg padding_value(%pad : f32) inner_dims_pos = [0, 1]
  inner_tiles = [8, 2] into %arg1 : tensor&lt;13x15xf32&gt; -&gt; tensor&lt;2x8x8x2xf32&gt;
</pre></div><a href="#g:14" id="g:14"><h1>pad</h1></a><div class="doc"><p><code>tensor.pad</code> is an operation that pads the <code>source</code> tensor
 with given <code>low</code> and <code>high</code> padding config.</p><p>The PadOp operation supports the following arguments:</p><ul><li>source: the &quot;base&quot; tensor on which to pad.</li><li>low: A list contains the padding along the start of each
        dimension, i.e <code>low</code>.</li><li>high: A list contains the padding along the end of each
         dimension, i.e. <code>high</code>.</li><li>nofold: indicates that the operation should not be folded when source and
           result types are equal.</li></ul><p>The result tensor dimensions are <code>low</code> + <code>dim</code> + <code>high</code> along that
 dimension. The number of elements of <code>low</code> and <code>high</code> must match
 the rank of the input tensor. They can be either a constant or a
 dynamic value.</p><p>The region of the <code>tensor.pad</code> operation returns the value to use
 for the padding. The arguments of the region represent the index
 of the source being accessed. There should be as many arguments as
 the rank of the <code>source</code> tensor. The value <code>yield</code>-ed by the
 region is used as the value of the view at the given position.</p><p>If <code>nofold</code> is set, the padding operation will not be folded away even
 if the source type and the padded type have the same static shape. This can
 be used, e.g., for packing or promotion to faster memory.</p><p>Example 1:</p><pre>  %pad_value = ... : f32
  %0 = tensor.pad %0 low[1, 2] high[2, 3] {
  ^bb0(%arg0 : index, %arg1 : index):
    tensor.yield %pad_value : f32
  } : tensor&lt;?x?xf32&gt; to tensor&lt;?x?xf32&gt;
</pre><p>Example 2:</p><pre>  %pad_value = ... : f32
  %0 = tensor.pad %arg0 low[2, %arg1, 3, 3] high[3, 3, %arg1, 2] {
  ^bb0(%arg2: index, %arg3: index, %arg4: index, %arg5: index):
      tensor.yield %pad_value : f32
  } : tensor&lt;1x2x2x?xf32&gt; to tensor&lt;6x?x?x?xf32&gt;
</pre><p>Example 3:</p><pre>  %pad_value = ... : f32
  %0 = tensor.pad %arg0 low[0, 0] high[%ub0, %ub1] {
  ^bb0(%arg1: index, %arg2: index):
    tensor.yield %pad_value : f32
  } : tensor&lt;2x3xf32&gt; to tensor&lt;?x?xf32&gt;
</pre><p>Example 4:</p><pre>  // Force a padded value to be always exist with <code>nofold</code>.
  %pad_value = ... : f32
  %0 = tensor.pad %arg0 nofold low[0, 0] high[0, 0] {
  ^bb0(%arg1: index, %arg2: index):
    tensor.yield %pad_value : f32
  } : tensor&lt;2x3xf32&gt; to tensor&lt;2x3xf32&gt;
</pre></div><a href="#g:15" id="g:15"><h1>parallel_insert_slice</h1></a><div class="doc"><p>The <code>parallel_insert_slice</code> yields a subset tensor value to its parent
 ParallelCombiningOpInterface. These subset tensor values are aggregated to
 in some unspecified order into a full tensor value returned by the parent
 parallel iterating op.
 The <code>parallel_insert_slice</code> is one such op allowed in the
 ParallelCombiningOpInterface op.</p><p>Conflicting writes result in undefined semantics, in that the indices written
 to by multiple parallel updates might contain data from any of the updates,
 or even a malformed bit pattern.</p><p>If an index is updated exactly once, the value contained at that index
 in the resulting tensor will be equal to the value at a corresponding index
 of a slice that was used for the updated. If an index is not updated at all,
 its value will be equal to the one in the original tensor.</p><p>This op does not create a new value, which allows maintaining a clean
 separation between the subset and full tensor.</p><p>Note that we cannot mark this operation as pure (Pures), even
 though it has no side effects, because it will get DCEd during
 canonicalization.</p><p>The parallel_insert_slice operation supports the following arguments:</p><ul><li>source: the tensor that is inserted.</li><li>dest: the tensor into which the source tensor is inserted.</li><li>offsets: tensor-rank number of offsets into the <code>dest</code> tensor into which
            the slice is inserted.</li><li>sizes: tensor-rank number of sizes which specify the sizes of the source
          tensor type.</li><li>strides: tensor-rank number of strides that specify subsampling in each
            dimension.</li></ul><p>The representation based on offsets, sizes and strides support a
 partially-static specification via attributes specified through the
 <code>static_offsets</code>, <code>static_sizes</code> and <code>static_strides</code> arguments. A special
 sentinel value ShapedType::kDynamic and
 ShapedType::kDynamic encodes that the corresponding entry has
 a dynamic value.</p><p>After buffer allocation, the &quot;parallel_insert_slice&quot; op is expected to lower
 into a memref.subview op.</p><p>A parallel_insert_slice operation may additionally specify insertion into a
 tensor of higher rank than the source tensor, along dimensions that are
 statically known to be of size 1.
 This rank-altering behavior is not required by the op semantics: this
 flexibility allows to progressively drop unit dimensions while lowering
 between different flavors of ops on that operate on tensors.
 The rank-altering behavior of tensor.parallel_insert_slice matches the
 rank-reducing behavior of tensor.insert_slice and tensor.extract_slice.</p><p>#### Verification in the rank-reduced case</p><p>The same verification discussion and mechanisms apply as for ExtractSliceOp.
 Unlike ExtractSliceOp however, there is no need for a specific inference.</p></div><a href="#g:16" id="g:16"><h1>rank</h1></a><div class="doc"><p>The <code>tensor.rank</code> operation takes a tensor operand and returns its rank.</p><p>Example:</p><pre>%0 = tensor.rank %arg0 : tensor&lt;*xf32&gt;
%1 = tensor.rank %arg1 : tensor&lt;?x?xf32&gt;
</pre></div><div class="top"><p class="src"><span class="keyword">pattern</span> <a id="v:Rank" class="def">Rank</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#Rank" class="link">Source</a> <a href="#v:Rank" class="selflink">#</a></p><div class="doc"><p>A pattern for <code>tensor.rank</code>.</p></div></div><div class="top"><p class="src"><a id="v:rank" class="def">rank</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#rank" class="link">Source</a> <a href="#v:rank" class="selflink">#</a></p><div class="doc"><p>A builder for <code>tensor.rank</code>.</p></div></div><a href="#g:17" id="g:17"><h1>reshape</h1></a><div class="doc"><p>The <code>reshape</code> operation converts a tensor from one type to an equivalent
 type with a provided shape. The source and destination types are compatible
 if both have the same element type, same number of elements. The following
 combinations are possible:</p><p>a. Source type is ranked or unranked. Shape argument has static size.
 Result type is ranked.</p><pre>// Reshape statically-shaped tensor.
%dst = tensor.reshape %src(%shape)
         : (tensor&lt;4x1xf32&gt;, tensor&lt;1xi32&gt;) -&gt; tensor&lt;4xf32&gt;
%dst0 = tensor.reshape %src(%shape0)
         : (tensor&lt;4x1xf32&gt;, tensor&lt;2xi32&gt;) -&gt; tensor&lt;2x2xf32&gt;
// Flatten unranked tensor.
%dst = tensor.reshape %src(%shape)
         : (tensor&lt;*xf32&gt;, tensor&lt;1xi32&gt;) -&gt; tensor&lt;?xf32&gt;
</pre><p>b. Source type is ranked or unranked. Shape argument has dynamic size.
 Result type is unranked.</p><pre>// Reshape dynamically-shaped 1D tensor.
%dst = tensor.reshape %src(%shape)
         : (tensor&lt;?xf32&gt;, tensor&lt;?xi32&gt;) -&gt; tensor&lt;*xf32&gt;
// Reshape unranked tensor.
%dst = tensor.reshape %src(%shape)
         : (tensor&lt;*xf32&gt;, tensor&lt;?xi32&gt;) -&gt; tensor&lt;*xf32&gt;
</pre></div><div class="top"><p class="src"><span class="keyword">pattern</span> <a id="v:Reshape" class="def">Reshape</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; operand -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#Reshape" class="link">Source</a> <a href="#v:Reshape" class="selflink">#</a></p><div class="doc"><p>A pattern for <code>tensor.reshape</code>.</p></div></div><div class="top"><p class="src"><a id="v:reshape" class="def">reshape</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#reshape" class="link">Source</a> <a href="#v:reshape" class="selflink">#</a></p><div class="doc"><p>A builder for <code>tensor.reshape</code>.</p></div></div><a href="#g:18" id="g:18"><h1>scatter</h1></a><div class="doc"><p>The <code>scatter</code> operation inserts a <code>source</code> tensor into a <code>dest</code> tensor at
 the given indices.</p><p>In its most general form, the tensor of indices specifies all the coordinates
 of every element to insert (i.e. COO format, without the payload).
 The indices are expected to be confined to coordinate values that fit the
 range of the <code>dest</code> tensor, otherwise the behavior is undefined.</p><p>The leading dimensions of the index tensor must match that of the dest
 tensor. The trailing dimensions of the dest tensor must match those of the
 source tensor by omitting the dimensions specified in scatter_dims
 (rank-reducing semantics) or setting them to <code>1</code> (rank-preserving semantics)
 (see examples).
 This convention allows an idiomatic specification and lowering of
 &quot;scattering multiple N-D slices into the dest tensor&quot;.
 The result type must match the type of the dest tensor.</p><p>Note: in the examples below, we separate out the indexing part of the tensor
 type by a whitespace for readability purposes.</p><p>Example:</p><pre>    // For each 1x2 triple of coordinates in %indices, insert the
    // element (i.e. 0-D subset) at the coordinates triple in %dest.
    //
    %out = tensor.scatter %source into %dest[%indices]
        scatter_dims([0, 1, 2]) unique :
      (tensor&lt;1x2x 1x1x1xf32&gt;, tensor&lt;4x4x4xf32&gt;, tensor&lt;1x2x 3xindex&gt;)
        -&gt; tensor&lt;4x4x4xf32&gt;

    // Note: source type may be further rank-reduced to tensor&lt;1x2x f32&gt;.
</pre><p>A slice variant is provided to allow specifying insertion of whole tensor
 slices into the <code>dest</code> tensor.</p><p>Example:</p><pre>    // For each 3 singleton of coordinates in %indices, insert the 2-D
    // slice into %dest[*, %indices[...]:%indices[...] + 1, *] with the
    // indices corresponding to the scatter_dims attribute specified by
    // %indices.
    //
    %out = tensor.scatter %source into %dest[%indices] scatter_dims([1]) unique :
      (tensor&lt;3x 4x1x6xf32&gt;, tensor&lt;4x5x6xf32&gt;, tensor&lt;3x 1xindex&gt;)
        -&gt; tensor&lt;4x5x6xf32&gt;
</pre><p>The dimensions specified in the scatter_dims attribute are ones for which the
 source tensor has size <code>1</code>.
 I.e. if the dest type is <code>axbxcxd</code> and the coordinates are [1, 3], then
 the source type suffix is <code>ax1xcx1</code>.
 Sactter also allows rank-reducing semantics where the shape <code>ax1xcx1</code> can be
 further simplified to <code>axc</code>.</p><p>The elemental type of the indices tensor can be any integer type.
 In the absence of target-specific or problem specific information the default
 type one should use is <code>index</code>.</p><p>This operation does not support unranked tensors.</p><p>A <code>unique</code> unit attribute must be be specified to indicate that the
 coordinates are statically guaranteed to be unique at runtime. If coordinates
 are not truly unique at runtime, the behavior is undefined.</p><p>Only full slices are meant to be supported by this op, if one desires
 partial slices (e.g. strided windows) one should compose this op with other
 tensor ops (e.g. tensor.insert_slice). This is to avoid a slippery slope of
 complexity that would make the op unusable in practice.</p><p>At the tensor-level, the index tensor is specified in an AoS form (i.e.
 coordinate tuple is the most minor). It is the responsibility of further
 lowerings and bufferiation to implement various concrete layouts.</p><p>Note: As currently specified, the operation must lower to an abstraction that
 performs copies to the output tensor. This is because the buffer type system
 is currently not rich enough to allow multiple non-contiguous views in the
 same type. This is visible more clearly in a notional buffer version of the
 op:</p><pre>    // memref&lt;?x 4xf32&gt; is a contiguous buffer of ?x4 elements, scatter into
    // random dest slices must copy to the contiguous dest.
    //
    some_side_effecting_op_writing_into %source, ...: memref&lt;3x 4xf32&gt;
    memref.scatter %source into %dest[%indices] scatter_dims([1]) unique :
      (memref&lt;3x 4xf32&gt;, memref&lt;?x 4xf32&gt;, memref&lt;?x 1xindex&gt;)

    // Nested buffer support in the producing op would allow writing directly
    // into the dest buffer.
    %v = some_nested_buffer_view_op %dest[%indices] scatter_dims([1]) unique :
      memref&lt;? x memref&lt;4xf32&gt;&gt;
    some_side_effecting_op_writing_into %v, ...: memref&lt;? x memref&lt;4xf32&gt;&gt;
</pre></div><a href="#g:19" id="g:19"><h1>splat</h1></a><div class="doc"><p>Broadcast the operand to all elements of the result tensor. The operand is
 required to be of integer<em>index</em>float type, and the result tensor must be
 statically shaped.</p><p>Example:</p><pre>%s = arith.constant 10.1 : f32
%t = tensor.splat %s : tensor&lt;8x16xf32&gt;
</pre><p>TODO: This operation is easy to extend to broadcast to dynamically shaped
       tensors:</p><pre>// Broadcasts %s to a 2-d dynamically shaped tensor, with %m, %n binding
// to the sizes of the two dynamic dimensions.
%m = &quot;foo&quot;() : () -&gt; (index)
%n = &quot;bar&quot;() : () -&gt; (index)
%t = tensor.splat %s [%m, %n] : tensor&lt;?x?xf32&gt;
</pre></div><div class="top"><p class="src"><span class="keyword">pattern</span> <a id="v:Splat" class="def">Splat</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#Splat" class="link">Source</a> <a href="#v:Splat" class="selflink">#</a></p><div class="doc"><p>A pattern for <code>tensor.splat</code>.</p></div></div><div class="top"><p class="src"><a id="v:splat" class="def">splat</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST.html#t:Type" title="MLIR.AST">Type</a> -&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#splat" class="link">Source</a> <a href="#v:splat" class="selflink">#</a></p><div class="doc"><p>A builder for <code>tensor.splat</code>.</p></div></div><a href="#g:20" id="g:20"><h1>unpack</h1></a><div class="doc"><p>The unpack operation converts a tensor with a tiled and packed layout to a
 lower-dimensional tensor. Similar to <code>pack</code>,  the mandatory attributes
 <code>inner_dims_pos</code> specifies a permutation for the inner data dimensions, while
 <code>inner_tiles</code> is the tiling factor. The attribute <code>outer_dims_perm</code> has the
 exact behavior as the one described in <code>pack</code>. In <code>unpack</code>, it is UB if the
 tile does not perfectly divide the dimension.</p><p>Example NCnc_to_NC:</p><pre>%0 = tensor.unpack %source inner_dims_pos = [0, 1]
  inner_tiles = [8, 32] into %dest : tensor&lt;16x8x8x32xf32&gt; -&gt; tensor&lt;128x256xf32&gt;
</pre><p>Example CK to KCck:</p><pre>%0 = tensor.unapck %source outer_dims_perm = [1, 0] inner_dims_pos = [0, 1]
  inner_tiles = [8, 32] into %dest : tensor&lt;8x16x8x32xf32&gt; -&gt; tensor&lt;128x256xf32&gt;
</pre></div><a href="#g:21" id="g:21"><h1>yield</h1></a><div class="doc"><p>This operation is used to yield a single value from a within a region. It
 is used to create dynamically sized tensors
 (see <code>tensor.generate</code> and <code>tensor.pad</code> ops).</p></div><div class="top"><p class="src"><span class="keyword">pattern</span> <a id="v:Yield" class="def">Yield</a> :: <a href="MLIR-AST.html#t:Location" title="MLIR.AST">Location</a> -&gt; operand -&gt; <a href="MLIR-AST.html#t:AbstractOperation" title="MLIR.AST">AbstractOperation</a> operand <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#Yield" class="link">Source</a> <a href="#v:Yield" class="selflink">#</a></p><div class="doc"><p>A pattern for <code>tensor.yield</code>.</p></div></div><div class="top"><p class="src"><a id="v:yield" class="def">yield</a> :: <a href="MLIR-AST-Builder.html#t:MonadBlockBuilder" title="MLIR.AST.Builder">MonadBlockBuilder</a> m =&gt; <a href="MLIR-AST-Builder.html#t:Value" title="MLIR.AST.Builder">Value</a> -&gt; m <a href="MLIR-AST-Builder.html#t:EndOfBlock" title="MLIR.AST.Builder">EndOfBlock</a> <a href="src/MLIR.AST.Dialect.Generated.Tensor.html#yield" class="link">Source</a> <a href="#v:yield" class="selflink">#</a></p><div class="doc"><p>A builder for <code>tensor.yield</code>.</p></div></div></div></div><div id="footer"><p>Produced by <a href="http://www.haskell.org/haddock/">Haddock</a> version 2.24.0</p></div></body></html>